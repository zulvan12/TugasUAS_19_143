Traceback (most recent call last):
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\jupyter_cache\executors\utils.py", line 51, in single_nb_execution
    executenb(
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 641, in run_until_complete
    return future.result()
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\lenovo-pc\AppData\Local\Programs\Python\Python310\lib\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
global c
page = requests.get("https://pta.trunojoyo.ac.id/c_search/byprod/7")
soup = BeautifulSoup(page.content, 'html.parser')
maxPage = soup.find_all(class_="pag_button")
maxPage = maxPage[4]
maxPage = maxPage.get('href')
maxPage = maxPage[-3:]
maxPage = int(maxPage)

for i in range(1, maxPage+1):
    # memindah halaman menuju halaman selanjutnya     
    src = f"https://pta.trunojoyo.ac.id/c_search/byprod/7/{i}"
    # counter untuk melihat progress berapa persen proses crawling
    print(f"Proses-{i//maxPage}%")
    # memanggil function getLinkToAbstract untuk mendapatkan setiap link ke halaman detail
    getLinkToAbstract(src)

# setelah memperoleh semua data abstract, data tersebut ditampung di list dataAbstract
# data perlu ditambahkan kolom index sebagai id
# looping berikut bertujuan menambahkan kolom index di setiap baris, lalu disimpan di list dataFix
for i in range(1, len(dataAbstract)+1):
    dataAbstract[i-1].insert(0, i)
    dataFix.append(dataAbstract[i-1])
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mNameError[0m                                 Traceback (most recent call last)
Input [1;32mIn [5][0m, in [0;36m<cell line: 10>[1;34m()[0m
[0;32m     14[0m     [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mProses-[39m[38;5;132;01m{[39;00mi[38;5;241m/[39m[38;5;241m/[39mmaxPage[38;5;132;01m}[39;00m[38;5;124m%[39m[38;5;124m"[39m)
[0;32m     15[0m     [38;5;66;03m# memanggil function getLinkToAbstract untuk mendapatkan setiap link ke halaman detail[39;00m
[1;32m---> 16[0m     [43mgetLinkToAbstract[49m[43m([49m[43msrc[49m[43m)[49m
[0;32m     18[0m [38;5;66;03m# setelah memperoleh semua data abstract, data tersebut ditampung di list dataAbstract[39;00m
[0;32m     19[0m [38;5;66;03m# data perlu ditambahkan kolom index sebagai id[39;00m
[0;32m     20[0m [38;5;66;03m# looping berikut bertujuan menambahkan kolom index di setiap baris, lalu disimpan di list dataFix[39;00m
[0;32m     21[0m [38;5;28;01mfor[39;00m i [38;5;129;01min[39;00m [38;5;28mrange[39m([38;5;241m1[39m, [38;5;28mlen[39m(dataAbstract)[38;5;241m+[39m[38;5;241m1[39m):

Input [1;32mIn [4][0m, in [0;36mgetLinkToAbstract[1;34m(src)[0m
[0;32m     15[0m tmp [38;5;241m=[39m crawlAbstract(item[38;5;241m.[39mget([38;5;124m'[39m[38;5;124mhref[39m[38;5;124m'[39m))
[0;32m     16[0m [38;5;66;03m# dataAbstract menampung data sementara hasil crawl[39;00m
[1;32m---> 17[0m [43mdataAbstract[49m[38;5;241m.[39mappend(tmp)

[1;31mNameError[0m: name 'dataAbstract' is not defined
NameError: name 'dataAbstract' is not defined

